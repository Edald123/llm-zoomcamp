{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The RAG Flow Cleaning and Modularizing Code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import minsearch\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_parse_json(filename):\n",
    "    with open(filename, 'rt') as f_in:\n",
    "        docs_raw = json.load(f_in)\n",
    "    \n",
    "    documents = []\n",
    "\n",
    "    for course_dict in docs_raw:\n",
    "        for doc in course_dict['documents']:\n",
    "            doc['course'] = course_dict['course']\n",
    "            documents.append(doc)\n",
    "\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_and_fit(documents):\n",
    "    index = minsearch.Index(\n",
    "        text_fields=[\"question\", \"text\", \"section\"],\n",
    "        keyword_fields=[\"course\"]\n",
    "    )\n",
    "\n",
    "    index.fit(documents)\n",
    "\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_openai_client():\n",
    "    load_dotenv()\n",
    "    api_key = os.getenv('OPENAI_API_KEY')\n",
    "    return OpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search function that takes a query and returns the search results\n",
    "def search(query, index):\n",
    "    boost = {'question': 3.0, 'section': 0.5}\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={'course': 'data-engineering-zoomcamp'},\n",
    "        boost_dict=boost,\n",
    "        num_results=5\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to build the prompt. It takes the query and the search results and returns the prompt\n",
    "def build_prompt(query, search_results):\n",
    "    prompt_template = \"\"\"\n",
    "    You're a course teaching assistant. A student asks you the following question.\n",
    "    Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "\n",
    "    QUESTION: {question}\n",
    "\n",
    "    CONTEXT: \n",
    "    {context}\n",
    "    \"\"\".strip()\n",
    "\n",
    "    context = \"\"\n",
    "\n",
    "    for doc in search_results:\n",
    "        context = context + f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\"\n",
    "\n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate the answer using the OpenAI API\n",
    "def llm(prompt, client):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function takes a query and returns the answer using the LLM model\n",
    "# It uses the search, build_prompt, and llm functions\n",
    "def rag(query, index, client): \n",
    "    search_results = search(query, index)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    answer = llm(prompt, client)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To run Kafka, the exact method will depend on whether you are using Java or Python. Here are the steps for both:\n",
      "\n",
      "### Java Kafka\n",
      "1. Navigate to your project directory.\n",
      "2. Use the following command in the terminal to run the Java producer:\n",
      "   ```bash\n",
      "   java -cp build/libs/<jar_name>-1.0-SNAPSHOT.jar:out src/main/java/org/example/JsonProducer.java\n",
      "   ```\n",
      "\n",
      "Replace `<jar_name>` with the actual name of your JAR file.\n",
      "\n",
      "### Python Kafka\n",
      "1. First, create a virtual environment and install the required packages:\n",
      "    ```bash\n",
      "    python -m venv env\n",
      "    source env/bin/activate  # For MacOS/Linux\n",
      "    # or\n",
      "    env\\Scripts\\activate  # For Windows\n",
      "    pip install -r path/to/requirements.txt\n",
      "    ```\n",
      "\n",
      "2. Make sure that Docker images required for your Kafka setup are up and running.\n",
      "3. After the virtual environment is activated, you can run your Python Kafka application.\n",
      "\n",
      "4. If you encounter a \"Permission denied\" error with `./build.sh`, you can fix it by running:\n",
      "    ```bash\n",
      "    chmod +x build.sh\n",
      "    ```\n",
      "\n",
      "Ensure you deactivate the virtual environment when you're done by running `deactivate`.\n",
      "\n",
      "### Fixing Common Issues\n",
      "- **For the \"ModuleNotFoundError: No module named 'kafka.vendor.six.moves'\" error**: Use the alternate package recommended:\n",
      "    ```bash\n",
      "    pip install kafka-python-ng\n",
      "    ```\n"
     ]
    }
   ],
   "source": [
    "documents = read_and_parse_json('documents.json')\n",
    "index = index_and_fit(documents)\n",
    "client = create_openai_client()\n",
    "query = \"how do I run kafka?\"\n",
    "\n",
    "print(rag(query, index, client))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
